== Proposed Refactorings

This chapter documents larger refactoring proposals that would significantly improve code quality but require careful planning and implementation.

=== LexemStream API Improvements

==== Problem Statement

The macro expansion and collation code (`collate()`, `replaceMacroArguments()`, etc.) in `src/yylex.c` suffers from *pointer parameter proliferation*, making it difficult to understand and maintain. Functions pass 5-6 separate parameters to track buffer state:

[source,c]
----
static char *collate(char *buffer, int *bufferSizeP, char **bufferWriteP, 
                     char **leftHandLexemP, char **rightHandLexemP, 
                     LexemStream *actualArgumentsInput);

static void copyRemainingLexems(char *buffer, int *bufferSize, char **bufferWriteP,
                                char *nextLexemP, char *endOfInputLexems);
----

This creates several issues:

* Hard to track which pointers point into which buffers
* Manual size/capacity management scattered throughout code
* Easy to make mistakes with pointer arithmetic
* Functions have 6+ parameters just for buffer management

==== Current Architecture

===== Three representations of lexem streams

The codebase currently uses three different ways to represent lexem streams:

*LexemBuffer* (structured, file-oriented)::
- Fixed-size embedded array: `char lexemStream[LEXEM_BUFFER_SIZE]`
- Metadata: `begin`, `read`, `write`, `position`, `fileOffset`, `backpatchPointer`
- Used for lexing from files/editor buffers
- Full API for manipulation: `putLexemCode()`, `getLexemCode()`, etc.

*LexemStream* (lightweight, pointer-based)::
- Just 3 pointers + metadata: `begin`, `read`, `write`, `macroName`, `inputType`
- Points to external memory (doesn't own it)
- Used for macro expansion pipelines
- *NO manipulation API - just raw pointer access*

*MacroBody* (persistent storage)::
- Pointer + length: `char *body`, `int size`
- Used for stored macro definitions

===== LexemStream buffer sources

LexemStream can point to 5 different memory sources:

1. `LexemBuffer.lexemStream` - Fixed array in file descriptor
2. `ppmAlloc()` - Preprocessor macro memory (dynamic)
3. `mbmAlloc()` - Macro body memory (dynamic)
4. `NULL` - Empty/missing arguments
5. External buffers from various sources

==== Proposed Solution

===== Add LexemStream manipulation API

Currently, LexemStream has *zero manipulation functions*. All operations are done via raw pointer manipulation. We need to add an API similar to LexemBuffer.

===== Phase 1: Extend LexemStream structure

Add optional buffer management fields:

[source,c]
----
typedef struct {
    char *begin;        // Start of buffer
    char *read;         // Current read position
    char *write;        // Current write position (= end for read-only)
    char *macroName;    // Name of macro this input represents
    InputType inputType;
    // NEW fields:
    int allocatedSize;  // Total allocated size (0 if not owned/unknown)
    bool ownsBuffer;    // Whether this LexemStream should manage/free the buffer
} LexemStream;
----

NOTE: Alternative considered but rejected: Create separate `WritableLexemStream` type. Pro: Cleaner separation of read vs write. Con: Yet another type, conversion overhead, more complex API.

===== Phase 2: Create manipulation API

New file: `src/lexinput.c` and extend `src/input.h`

====== Core buffer management

[source,c]
----
// Creation
LexemStream lexInputCreateOwned(int initialSize);     // Allocates managed buffer
LexemStream lexInputCreateView(char *begin, char *end); // Read-only view

// Capacity management
void lexInputEnsureCapacity(LexemStream *input, int additionalBytes);
void lexInputReallocIfNeeded(LexemStream *input, int needed);
int lexInputRemainingCapacity(LexemStream *input);

// Reading (advance read pointer)
LexemCode lexInputGetLexem(LexemStream *input);
LexemCode lexInputPeekLexem(LexemStream *input);  // Don't advance
bool lexInputHasMore(LexemStream *input);          // read < write
void lexInputSkipLexem(LexemStream *input);        // Skip current lexem

// Writing (advance write pointer)
void lexInputPutLexemCode(LexemStream *output, LexemCode lexem);
void lexInputPutLexemPosition(LexemStream *output, Position pos);
void lexInputAppendBytes(LexemStream *dest, char *src, int len);
void lexInputCopyLexem(LexemStream *dest, LexemStream *src); // Copy one lexem from src to dest

// Cleanup
void lexInputFree(LexemStream *input);  // Only frees if ownsBuffer=true
----

===== Phase 3: Refactor functions to use LexemStream API

====== Example: collate() before

[source,c]
----
static char *collate(char *buffer,              // Destination buffer
                     int *bufferSizeP,          // Destination allocated size
                     char **bufferWriteP,       // Current write position
                     char **leftHandLexemP,     // Left operand read position
                     char **rightHandLexemP,    // Right operand read position
                     LexemStream *actualArgumentsInput)  // Source arguments
{
    // Manual buffer management scattered throughout:
    *bufferSizeP = expandPreprocessorBufferIfOverflow(buffer, *bufferSizeP, *bufferWriteP);
    
    // Manual pointer arithmetic:
    int lexemLength = nextInputLexemP - lexemStart;
    memcpy(*bufferWriteP, lexemStart, lexemLength);
    *bufferWriteP += lexemLength;
    
    // Complex state tracking:
    char *lhs = *leftHandLexemP;
    char *endOfLexems = NULL;
    // ... many lines of pointer manipulation
}
----

====== Example: collate() after

[source,c]
----
static void collate(LexemStream *output,           // Destination (manages its own buffer)
                    LexemStream *leftOperand,      // Left operand (with read position)
                    LexemStream *rightOperand,     // Right operand (with read position)
                    LexemStream *actualArgumentsInput)
{
    // Clean, high-level operations:
    lexInputEnsureCapacity(output, estimatedSize);
    
    // Copy operations are explicit and clear:
    lexInputCopyLexem(output, leftOperand);
    lexInputCopyLexem(output, rightOperand);
    
    // State is encapsulated in LexemStream structures
}
----

====== Functions to refactor (priority order)

1. *collate()* - Most complex, biggest win (yylex.c:1515)
2. *copyRemainingLexems()* - Used by collate (yylex.c:1450)
3. *resolveMacroArgumentAsLeftOperand()* - Complex pointer tracking (yylex.c:1465)
4. *replaceMacroArguments()* - Many buffer operations (yylex.c:1717)
5. *expandMacroArgument()* - Buffer management (yylex.c:1362)
6. *createMacroBodyAsNewInput()* - Multiple buffers (yylex.c:1780)

==== Benefits

===== Code clarity
* Functions have 2-3 parameters instead of 6+
* Clear ownership and boundaries
* Self-documenting code (LexemStream instead of 3 raw pointers)

===== Maintainability
* Centralized buffer management logic
* Easier to add bounds checking
* Less error-prone

===== Consistency
* Similar philosophy to LexemBuffer
* Uniform API for lexem stream operations

==== Implementation Strategy

Step 1: Add new fields to LexemStream (backward compatible)::
- Initialize `allocatedSize = 0` and `ownsBuffer = false` for all existing uses
- No functional changes yet

Step 2: Create lexinput.c with basic API::
- Implement core functions: create, ensure capacity, append, copy
- Add unit tests

Step 3: Refactor one function as proof of concept::
- Start with `copyRemainingLexems()` (simplest)
- Validate approach works

Step 4: Refactor remaining functions::
- Work through priority list
- Update call sites incrementally

Step 5: Cleanup::
- Remove old helper functions if no longer needed
- Update documentation

==== Risks and Mitigation

===== Risk: Breaking existing code

*Mitigation:* 

* Make LexemStream changes backward compatible
* Add new fields with safe defaults
* Refactor incrementally, one function at a time
* Run full test suite after each change

===== Risk: Performance regression

*Mitigation:*

* Keep buffer operations inline where critical
* Profile before/after
* The current code already does realloc, just manually

===== Risk: Memory leaks from ownsBuffer confusion

*Mitigation:*

* Clear ownership semantics in documentation
* Consider using explicit create/destroy pairs
* Add assertions for debugging

==== Notes

===== Why not unify with LexemBuffer?

LexemBuffer and LexemStream serve different purposes:

* *LexemBuffer*: Heavy, file-oriented, owns fixed-size array, lots of metadata
* *LexemStream*: Lightweight, flexible views, points to various sources

Trying to unify them would make both worse. The real issue is LexemStream lacks manipulation functions, not that two types exist.

===== Backward compatibility

The proposed changes are designed to be backward compatible:

* New fields default to "not owned, size unknown" (0, false)
* Existing code that creates LexemStream with `makeLexemStream()` continues to work
* Only new code uses the enhanced API

==== Open Questions

. Should `lexInputEnsureCapacity()` use ppmAlloc or mbmAlloc?
** Probably depends on context - may need separate functions or a memory source parameter

. How to handle the transition from raw pointers to LexemStream?
** Some functions receive raw pointers from outside (e.g., from MacroBody.body)
** May need wrapper functions to create temporary LexemStream views

. Should we add debug assertions for bounds checking?
** Would help catch errors during development
** Could be compiled out in production

==== References

* Current code: `src/yylex.c` lines 1362-1823 (macro expansion)
* LexemBuffer API: `src/lexembuffer.h` and `src/lexembuffer.c`
* Current LexemStream: `src/input.h` and `src/input.c`

==== Related Issues

This refactoring addresses the root cause identified in the discussion about replacing the malloc-based macro body memory system (commit e1d506f7). The memory tracking issues stem from the complexity of managing multiple pointer parameters across function boundaries.

---

TIP: When implementing this refactoring, consider starting with unit tests for the new API functions before refactoring existing code. This will help validate the design and provide safety during migration.

[[clean-persistence-store]]
=== Clean Persistence Store Abstraction

==== Problem Statement

The `cxfile` module currently mixes multiple responsibilities that should be separated:

* **Persistence implementation** (reading/writing .cx files) ✓ Correct level
* **Search and filter operations** (matching search strings) ✗ Wrong level
* **Operation-specific loading** (menu creation, macro completion, unused detection) ✗ Too specific
* **Treated as source of truth** (when it should be just a cache) ✗ Architectural confusion

This mixing creates tight coupling, makes testing difficult, and prevents future architectural improvements (like LSP integration or alternative storage backends).

==== Architectural Confusion: In-Memory vs Persistence

The current code conflates two distinct concepts:

*Reference Database* (Smart Layer - Source of Truth)::
- **Always in-memory**: The `referenceableItemTable` hash table
- Answers queries fast from RAM
- Decides when to load from persistence
- Decides when to save to persistence
- Manages invalidation and staleness
- **This is the actual database**

*Persistence Store* (Dumb Layer - Durable Cache)::
- **Always on disk/database**: The `.cx` files (or future SQLite, etc.)
- Just knows how to save/load a specific format
- Has NO in-memory state of its own
- No business logic, no searching, no filtering
- **This is just the storage mechanism**

IMPORTANT: The persistence layer is **always about durable storage** that survives restarts. "In-memory persistence" is a contradiction - persistence means surviving across sessions.

==== Current Architecture Problems

===== Mixed Abstraction Levels

The current `cxfile.h` public interface exposes:

[source,c]
----
// Operation-specific scanning (too high-level for storage)
extern void scanReferencesToCreateMenu(char *symbolName);
extern void scanForMacroUsage(char *symbolName);
extern void scanForGlobalUnused(char *cxrefFileName);
extern void scanForSearch(char *cxrefFileName);

// Implementation details leaked (partitioning is internal)
extern int cxFileHashNumberForSymbol(char *symbol);
extern void searchSymbolCheckReference(ReferenceableItem *item, Reference *ref);

// Generic API (already identified as "Abstract API")
extern bool loadFileNumbersFromStore(void);
extern void ensureReferencesAreLoadedFor(char *symbolName);
extern void saveReferencesToStore(bool updating, char *name);
----

Problems:

* **Four `scan*` functions**: Encode specific use cases (menu, macro, unused, search) instead of providing generic operations
* **Implementation details exposed**: `cxFileHashNumberForSymbol()` is a partitioning optimization that shouldn't be public
* **Search logic in storage**: `searchSymbolCheckReference()` mixes filtering with persistence
* **Side-effect heavy**: All functions mutate global `referenceableItemTable` implicitly

===== Tight Coupling to Use Cases

Currently `cxfile.c` knows about:

* Browser menus (`scanReferencesToCreateMenu`)
* Macro completion (`scanForMacroUsage`)
* Unused symbol detection (`scanForGlobalUnused`)
* Symbol search (`scanForSearch`)

A persistence layer shouldn't know about any of these! These are *clients* of storage, not responsibilities of storage.

===== Wrong Source of Truth

From the navigation debugging (see Insights chapter), we discovered:

[source,c]
----
// In cxref.c - loads FROM DISK directly
scanReferencesToCreateMenu(symbolName);  // Treats .cx files as truth
----

This bypasses the in-memory `referenceableItemTable`, treating disk as authoritative. But the **actual truth** is:

----
referenceableItemTable = Disk state (.cx files) + Preloaded editor buffers
----

The disk is just a **cache** of the last saved state, not the current truth.

==== Proposed Architecture

===== Two-Layer Design

[source]
----
┌──────────────────────────────────────────────────┐
│  Reference Database (Smart Layer)                │
│  Source of Truth: referenceableItemTable (RAM)   │
│                                                  │
│  - Fast in-memory queries                        │
│  - Knows what's current vs stale                 │
│  - Handles invalidation/refresh                  │
│  - Decides when to load/save                     │
│  - Unified interface for all clients             │
└──────────────────────────────────────────────────┘
                      ↓
        (only when loading/saving needed)
                      ↓
┌──────────────────────────────────────────────────┐
│  Persistence Store (Dumb Layer)                  │
│  Durable Cache: .cx files on disk                │
│                                                  │
│  - Just save/load binary format                  │
│  - No business logic                             │
│  - No in-memory state                            │
│  - Can be swapped (SQLite, Protobuf, etc.)       │
└──────────────────────────────────────────────────┘
----

===== Clean Persistence Store Interface

[source,c]
----
// persistence_store.h - Pure storage operations
#ifndef PERSISTENCE_STORE_H_INCLUDED
#define PERSISTENCE_STORE_H_INCLUDED

#include "referenceableitem.h"

/* ============================================
 * Store Lifecycle
 * ============================================ */

// Load metadata (file numbers, timestamps)
extern bool persistenceLoadMetadata(void);

// Persist all references to durable storage
extern void persistenceSaveAll(bool updating, char *location);

/* ============================================
 * Reference Loading (into referenceableItemTable)
 * ============================================ */

// Load references for specific symbol into memory table
// Returns true if symbol found in storage
extern bool persistenceLoadSymbol(char *symbolName);

/* ============================================
 * Bulk Scanning
 * ============================================ */

// Scan entire storage, calling visitor for each reference
// Visitor decides what to do with each reference
typedef void (*PersistenceVisitor)(ReferenceableItem *item,
                                    Reference *ref,
                                    void *context);
extern void persistenceScanAll(PersistenceVisitor visitor, void *context);

#endif
----

===== Reference Database Interface

This layer provides the "smart" operations that clients actually need:

[source,c]
----
// reference_database.h - Smart operations (initially thin wrapper)
#ifndef REFERENCE_DATABASE_H_INCLUDED
#define REFERENCE_DATABASE_H_INCLUDED

#include "referenceableitem.h"
#include "position.h"

// Initialize the in-memory reference database
extern bool refDbInitialize(void);

// Lookup symbol in the in-memory table
// Automatically loads from persistence if not in memory
extern ReferenceableItem* refDbLookupSymbol(char *name);

// Get all references for a symbol
// Ensures data is loaded and current
extern Reference* refDbGetReferences(char *symbolName);

// Mark a file's references as stale (needs reload)
extern void refDbInvalidateFile(int fileNumber);

// Persist the current in-memory state
extern void refDbSave(bool updating, char *location);

#endif
----

NOTE: This interface starts simple but is where the *Unified Symbol Database* refactoring (next section) will add smart on-demand loading, dependency tracking, and invalidation logic.

==== Migration Strategy

===== Phase 1: Create Clean Boundaries (No Behavior Change)

. Rename `cxfile.h` → `cxfile_internal.h` (implementation detail)
. Create `persistence_store.h` with clean interface
. Create `persistence_store.c` that delegates to `cxfile_*` functions
. Update all callers to use `persistence_store.h` instead of `cxfile.h`

Result: Same behavior, cleaner names, clear intent.

===== Phase 2: Extract Operation Logic

Move operation-specific logic OUT of persistence layer:

*Search Logic*:: `searchSymbolCheckReference()` → new `search.c` module
+
[source,c]
----
// Before: In cxfile.c (WRONG LEVEL)
void searchSymbolCheckReference(ReferenceableItem *item, Reference *ref) {
    if (searchStringMatch(...)) {
        reportMatch(item, ref);
    }
}

// After: In search.c (RIGHT LEVEL)
void searchForSymbol(char *pattern) {
    persistenceScanAll(checkSearchMatch, pattern);
}

static void checkSearchMatch(ReferenceableItem *item, Reference *ref, void *ctx) {
    if (searchStringMatch(item->linkName, (char *)ctx)) {
        reportMatch(item, ref);
    }
}
----

*Unused Detection*:: Extract from `cxfile.c` to `refactorings.c` or new `analysis.c`

*Menu Creation*:: Keep in `cxref.c` but use clean `refDbGetReferences()` instead of direct disk scanning

===== Phase 3: Hide Implementation Details

Make these functions `static` (internal to cxfile.c):

* `cxFileHashNumberForSymbol()` - partitioning is implementation detail
* `searchSymbolCheckReference()` - moved to search module
* All internal scanning logic

===== Phase 4: Consolidate Scanning Functions

Replace four specific scanners with generic visitor pattern:

[cols="1,1"]
|===
|Old (Use-Case Specific) |New (Generic)

|`scanReferencesToCreateMenu(name)`
|`refDbGetReferences(name)`

|`scanForMacroUsage(name)`
|`refDbGetReferences(name)`

|`scanForGlobalUnused(location)`
|`persistenceScanAll(checkUnused, ctx)`

|`scanForSearch(location)`
|`persistenceScanAll(checkMatch, pattern)`
|===

==== Benefits

*Testability*:: Can mock `persistence_store.h` for testing navigation without .cx files
+
*Future Storage Backends*:: Could implement with SQLite, in-memory testing mock, or different binary format
+
*Clear Boundaries*:: Storage vs search vs navigation clearly separated
+
*Simpler Interface*:: 4 functions instead of 9, clearer responsibilities
+
*Less Coupling*:: Parsing code doesn't call storage directly, goes through reference database
+
*LSP Readiness*:: Reference database layer is where LSP `textDocument/didChange` integration will live

==== Relationship to Unified Symbol Database

This refactoring is the **foundation** for the larger *Unified Symbol Database Architecture* (next section):

* **Clean persistence layer** enables swapping storage backends without affecting clients
* **Reference database layer** is where smart on-demand loading logic will live
* **Separation of concerns** makes the unified architecture clearer

Migration path:

. First: Clean up persistence (this refactoring)
. Then: Add smart on-demand logic to reference database (next refactoring)
. Finally: Both Emacs and LSP use same unified code path

==== Implementation Checklist

- [ ] Create `persistence_store.h` with proposed interface
- [ ] Create `persistence_store.c` delegating to cxfile
- [ ] Rename `cxfile.h` → `cxfile_internal.h`
- [ ] Create `reference_database.h` (thin wrapper initially)
- [ ] Create `reference_database.c` delegating to persistence
- [ ] Update all callers to use new interfaces
- [ ] Move search logic from cxfile to search module
- [ ] Move unused detection logic to appropriate module
- [ ] Make `cxFileHashNumberForSymbol` static
- [ ] Make `searchSymbolCheckReference` static or remove
- [ ] Add unit tests for both interfaces
- [ ] Update documentation

==== References

* Current implementation: `src/cxfile.c`, `src/cxfile.h`
* In-memory table: `src/reftab.c` (referenceableItemTable)
* Navigation architecture: Chapter 17 (Insights) - Navigation Architecture section

[[unified-symbol-database]]
=== Unified Symbol Database Architecture

==== Problem Statement

The current symbol database has evolved from a batch cross-referencer (like `ctags`) with artificial distinctions between "file-based" and "on-demand" modes. This creates:

* **Mode complexity**: Different code paths for Emacs vs LSP clients
* **Cold start problems**: Requires upfront `-create` operation before use
* **Manual updates**: Users must remember to run `-update` after changes
* **Inconsistent behavior**: Different modes provide different guarantees
* **Maintenance overhead**: Multiple implementations to maintain and test

==== Current Architecture Limitations

The existing system distinguishes between:

[cols="1,1,1"]
|===
|Aspect |File-Based Mode |On-Demand Mode

|**Cold Start**
|Requires `-create` first
|Parse file immediately

|**Warm Queries**
|O(1) hash lookup
|O(file_size) parsing

|**Memory Usage**
|Low (streaming)
|High (in-memory cache)

|**Incremental Updates**
|Smart file tracking
|Per-file invalidation

|**Multi-project**
|Separate databases
|Workspace-scoped
|===

==== Proposed Solution

===== Core Insight: Unified On-Demand Architecture

Both Emacs and LSP clients want the same thing: **up-to-date symbol and reference information**. The distinction between "file-based" and "on-demand" modes is artificial complexity. Instead, c-xrefactory should provide a unified interface that:

1. **Always ensures information is current** using existing dependency tracking
2. **Scans incrementally** only what's needed, when needed  
3. **Uses `.cx` files as persistent cache** for optimization
4. **Eliminates cold start problems** by avoiding upfront full-project scanning

===== Simplified Interface Design

[source,c]
----
typedef struct SymbolDatabase SymbolDatabase;

typedef struct {
    // Unified operations for any client (Emacs or LSP)
    Symbol* (*lookupSymbol)(SymbolDatabase* db, const char* name, Position pos);
    ReferenceList* (*getReferences)(SymbolDatabase* db, const char* name, Position pos);
    ReferenceList* (*getOccurrences)(SymbolDatabase* db, const char* name, Position pos);
    
    // All complexity hidden in implementation:
    // - File modification checking (existing: checkFileModifiedTime)
    // - Include dependency tracking (existing: cachedIncludedFilePass) 
    // - Incremental scanning (existing: makeIncludeClosureOfFilesToUpdate)
    // - Persistent caching (existing: .cx file system)
} SymbolDatabaseOperations;
----

===== Implementation Strategy: Smart On-Demand

IMPORTANT: This refactoring builds on the *Clean Persistence Store* foundation (previous section). The smart logic lives in the **in-memory reference database layer**, while `.cx` files remain a **durable cache** for persistence.

The implementation leverages **existing sophisticated logic**:

[source,c]
----
Symbol* lookupSymbol(const char* name, Position pos) {
    // 1. Check if in-memory table has current information
    if (refTableHasCurrent(name, pos)) {
        return lookupInMemoryTable(name, pos);  // Answer from RAM
    }

    // 2. Load from persistence if not in memory
    if (!refTableHasSymbol(name)) {
        persistenceLoadSymbol(name);  // Load .cx into referenceableItemTable
    }

    // 3. Check if loaded data is stale (file modified since load)
    if (refTableDataIsStale(name, pos)) {
        // Use existing dependency tracking to scan minimal set
        FileList* filesToScan = calculateDependencyClosure(pos.file);
        for (FileItem* file : filesToScan) {
            if (checkFileModifiedTime(file->fileNumber)) {
                parseFileAndUpdateTable(file);  // Reparse into memory
            }
        }
    }

    // 4. Answer from in-memory table (now guaranteed current)
    return lookupInMemoryTable(name, pos);
}
----

**Architectural Layers:**

----
Query → Reference Database (in-memory, smart) → Persistence Store (disk, dumb)
        ↑                                         ↑
        Always answers from RAM                   Only for load/save
----

**Key Benefits:**

* **No artificial modes** - same code path for all clients
* **No cold start** - first lookup triggers minimal necessary scanning
* **Incremental by design** - only scans files that need updating
* **In-memory speed** - all queries answered from RAM (referenceableItemTable)
* **Durable cache** - `.cx` files persist state across sessions
* **Existing logic reuse** - leverages proven dependency tracking system

===== Legacy Architecture Recognition

c-xrefactory evolved from a **batch cross-referencer** (like `ctags`) and was enhanced for real-time use:

[source,bash]
----
# Legacy batch workflow:
c-xref -create project.c     # Full scan, build .cx database
c-xref -update modified.c    # Incremental update
c-xref -olcxpush symbol      # Query pre-built database

# Unified approach:
c-xref -server               # Start server, scan on-demand as needed
c-xref -lsp                  # Same logic, different protocol
----

IMPORTANT: The `.cx` files are a **durable cache** that persists the in-memory `referenceableItemTable` between sessions. They are an optimization, not the database itself. The actual database is always in RAM.

==== Implementation Plan

===== Phase 1: Interface Unification

* Create unified `SymbolDatabase` interface
* Wrap existing logic in smart on-demand implementation
* Replace explicit `-create`/`-update` commands with automatic dependency checking
* Both Emacs and LSP use same code path

===== Phase 2: Optimization

* Enhance existing dependency tracking for finer-grained invalidation
* Optimize in-memory caching strategies
* Background `.cx` file maintenance for long-running sessions
* Performance tuning for large codebases

==== Benefits

===== Architectural Simplification

* **Single code path** for both Emacs and LSP clients - eliminates maintenance overhead
* **No mode distinctions** - same smart logic serves all use cases optimally
* **Leverages existing logic** - reuses proven dependency tracking and caching systems
* **Reduced complexity** - eliminates artificial FILE_BASED/ON_DEMAND/HYBRID modes

===== User Experience Improvements

* **Zero configuration** - works immediately on any C project without setup
* **No cold start delay** - first symbol lookup triggers minimal necessary scanning
* **Transparent caching** - `.cx` files automatically maintained as performance optimization
* **Consistent behavior** - same results whether using Emacs or modern IDE with LSP

===== Performance Characteristics

* **Minimal initial cost** - avoids expensive upfront full-project scanning
* **Smart incremental updates** - only rescans files that have actually changed
* **Automatic dependency tracking** - includes files affected by changes get updated
* **Persistent optimization** - analysis results cached across sessions

===== Development Benefits

* **Backward compatibility** - existing Emacs workflows continue unchanged
* **Forward compatibility** - natural path to modern LSP integration
* **Reduced maintenance** - single implementation instead of multiple modes
* **Enhanced testability** - unified logic easier to test comprehensively

==== Existing Infrastructure

===== Sophisticated Dependency Tracking

The unified approach leverages c-xrefactory's **existing sophisticated dependency management** that handles include file relationships automatically:

**File Modification Tracking** (`filetable.h`):

[source,c]
----
typedef struct fileItem {
    char *name;
    time_t lastModified;        // Last known modification time
    time_t lastInspected;       // Last time we checked
    time_t lastUpdateMtime;     // Last update cycle time  
    time_t lastFullUpdateMtime; // Last full update time
    // ... scheduling and state flags
} FileItem;

bool checkFileModifiedTime(int fileNumber);
----

**Include Dependency Tracking** (`yylex.c`):

[source,c]
----
void pushInclude(FILE *file, EditorBuffer *buffer, char *name, char *prepend) {
    // ... setup include stack
    includeStack.stack[includeStack.pointer++] = currentFile;
    // Track include relationships for dependency analysis
}
----

**Automatic Include Closure** (`xref.c:81-108`):

[source,c]
----
static void makeIncludeClosureOfFilesToUpdate(void) {
    // If file A includes file B, and B is modified, A gets scheduled for update
    // This uses the reference database to track include relationships
    bool fileAddedFlag = true;
    while (fileAddedFlag) {
        // Iterative closure: keeps adding dependent files until stable
        for (all scheduled files) {
            find_all_files_that_include_this_file();
            schedule_them_for_update();
        }
    }
}
----

IMPORTANT: This dependency tracking infrastructure is **already production-ready** and handles the complex cases (transitive dependencies, modification time checking, include stack management). The unified symbol database can leverage this existing logic instead of reimplementing dependency management.

==== Open Questions

. Should we maintain backward compatibility with explicit `-create`/`-update` commands?
** Probably yes, at least as no-ops or aliases to make transition easier

. How to handle very large projects (>1M LOC)?
** May need workspace-level configuration for incremental scanning thresholds
** Consider lazy loading of symbol data

. What's the migration path for existing users?
** Existing `.cx` files should continue to work
** Auto-migrate on first run with new version
** Provide clear documentation on new behavior

==== References

* Current implementation: `src/cxfile.c`, `src/xref.c`
* File tracking: `src/filetable.h`, `src/filetable.c`
* Dependency tracking: `src/xref.c` lines 81-108
* Current database description: See chapter 08 (Code) - Reference Database section

[[macro-expansion-module]]
=== Extract Macro Expansion Module

==== Problem Statement

The `yylex.c` file is **2353 lines** and combines multiple responsibilities:

* Lexical analysis and token reading
* File and buffer management
* Preprocessor directive processing
* **Macro expansion system** (~800 lines)

The macro expansion code is a substantial, cohesive subsystem that would benefit from extraction into its own module. Currently, it's deeply embedded in yylex.c, making both lexing and macro expansion harder to understand and test in isolation.

==== Current Architecture

The macro expansion system in `yylex.c` comprises:

===== Core Responsibilities (~800 lines)

* **Macro call expansion** - Main orchestration (`expandMacroCall()`)
* **Argument processing** - Collection and recursive expansion
* **Token collation** - `##` operator implementation
* **Stringification** - `#` operator implementation
* **Memory management** - Separate arenas for macro bodies (MBM) and arguments (PPM)
* **Cyclic detection** - Preventing infinite macro recursion

===== Key State

[source,c]
----
int macroStackIndex;  // Current macro expansion depth
static LexemStream macroInputStack[MACRO_INPUT_STACK_SIZE];
static Memory macroBodyMemory;      // Long-lived: macro definitions
static Memory macroArgumentsMemory; // Short-lived: expansion temporaries
----

===== Memory Lifetime Separation

The system uses **two distinct memory arenas** with different lifetimes:

* **MBM (Macro Body Memory)**: Persistent storage for macro definitions throughout compilation
* **PPM (PreProcessor Memory)**: Temporary storage for expansion, collation, and argument processing

This separation is fundamental and should be preserved in any refactoring.

==== Proposed Solution

Extract macro expansion into a new module: `macroexpansion.c/h`

===== Public Interface

The new module would expose a minimal, focused API:

[source,c]
----
// Initialization
void initMacroExpansion(void);
int getMacroBodyMemoryIndex(void);
void setMacroBodyMemoryIndex(int index);

// Core expansion
bool expandMacroCall(Symbol *macroSymbol, Position position);
bool insideMacro(void);
int getMacroStackDepth(void);

// Memory allocation (exposed for macro definition processing)
void *macroBodyAlloc(size_t size);
void *macroBodyRealloc(void *ptr, size_t oldSize, size_t newSize);
void *macroArgumentAlloc(size_t size);
----

===== Module Boundaries

*What moves to macroexpansion.c:*

* Macro call expansion and argument processing
* Token collation (`collate()` and helpers)
* Stringification (`macroArgumentsToString()`)
* Cyclic call detection
* MBM/PPM memory management
* Buffer expansion utilities (`expandPreprocessorBufferIfOverflow()`, etc.)

*What remains in yylex.c:*

* Lexing and file input
* Preprocessor directive processing (`#define`, `#ifdef`, etc.)
* Include file handling
* Main `yylex()` function
* Macro symbol table operations

*Dependencies:*

The macro module would depend on:

* Lexem stream operations (reading/writing)
* Symbol lookup (`findMacroSymbol()`)
* Cross-referencing (for collation and expansion references)
* Current input state (via accessor functions)

==== Benefits

===== Architectural

* **Separation of concerns**: Lexing vs. preprocessing clearly separated
* **Reduced file size**: yylex.c drops from 2353 → ~1550 lines (34% reduction)
* **Testability**: Macro expansion can be unit tested independently
* **Clearer ownership**: Macro state and memory management centralized

===== Maintainability

* **Focused modules**: Each file has a single, clear purpose
* **Easier reasoning**: Macro behavior isolated from lexer concerns
* **Better documentation**: Module-level documentation for macro system

===== Future flexibility

* Could support different macro systems (C vs. C++)
* Easier to add macro debugging/tracing
* Independent optimization of macro expansion

==== Implementation Strategy

===== Phase 1: Preparation (Already Complete)

✓ Create `LexemBufferDescriptor` type for buffer management +
✓ Refactor buffer expansion functions to use descriptor +
✓ Eliminate return values for size updates

===== Phase 2: Create Module Structure

* Create `macroexpansion.h` with public interface
* Create `macroexpansion.c` with initial implementations
* Move `LexemBufferDescriptor` to appropriate header
* Create accessor functions for `currentInput` state

===== Phase 3: Incremental Function Migration

Move functions in this order (lowest risk first):

1. **Memory management** - MBM/PPM allocation functions
2. **Buffer expansion** - `expandPreprocessorBufferIfOverflow()`, `expandMacroBodyBufferIfOverflow()`
3. **Support utilities** - `cyclicCall()`, `prependMacroInput()`
4. **Token processing** - `collate()`, `resolveMacroArgument()`, etc.
5. **Core expansion** - `expandMacroCall()`, `createMacroBodyAsNewStream()`, etc.

===== Phase 4: Integration and Cleanup

* Update yylex.c to use new interface
* Run full test suite after each migration step
* Add focused unit tests for macro expansion
* Update build system
* Document the new architecture

==== Risks and Mitigation

===== Risk: Complex dependencies

*Mitigation:*

* Create clear accessor functions for shared state
* Use incremental approach - one function group at a time
* Validate with tests after each step

===== Risk: Performance overhead

*Mitigation:*

* Keep critical functions inline where necessary
* Profile before/after migration
* Current code already has abstraction layers

*Assessment:* Low risk - macro operations are complex enough that function call overhead is negligible

===== Risk: Breaking existing tests

*Mitigation:*

* Run test suite after every migration step
* Keep interface behavior identical
* Use compiler to catch interface mismatches

==== Success Metrics

* All existing tests pass
* yylex.c reduced to ~1550 lines
* New focused tests for macro expansion added
* No performance regression (< 5% overhead acceptable)
* Code review confirms improved clarity

==== Open Questions

. Should `findMacroSymbol()` move to the macro module or stay in yylex.c?
** It's used by both lexer (for expansion triggering) and macro module (for nested expansions)
** Probably belongs in a shared location or as part of symbol table operations

. How to handle `currentInput` global state?
** Options: Pass explicitly, use accessor functions, or provide context structure
** Accessor functions likely cleanest: `getCurrentInput()`, `setCurrentInput()`

. Should we extract preprocessor directives at the same time?
** No - keep changes focused
** Could be a future refactoring after macro extraction proves successful

==== References

* Current code: `src/yylex.c` lines 1327-2089 (macro expansion system)
* Memory management: `src/memory.h`, `src/memory.c`
* Symbol operations: `src/symbol.h`
* Related refactoring: <<LexemStream API Improvements>> addresses buffer management patterns

---

NOTE: This refactoring is independent of the LexemStream API improvements but would benefit from them being completed first, as they simplify buffer management patterns throughout the macro expansion code.

== Roadmap

This chapter outlines the development roadmap for c-xrefactory, tracking completed work, current priorities, and future architectural goals.

=== Guiding Principles

The roadmap is guided by these principles:

* **Incremental improvement**: Each step should provide immediate value while moving toward long-term goals
* **Test-driven modernization**: Maintain ~80% test coverage to enable confident refactoring
* **Backward compatibility**: Preserve existing Emacs workflows while enabling modern IDE integration
* **Architectural simplification**: Replace artificial mode distinctions with unified, smart on-demand behavior
* **Legacy code respect**: Work with the existing 1990s codebase thoughtfully, not against it

=== Recent Accomplishments (2025 Q1)

==== C Preprocessor Compliance Fixes

**Problem**: c-xrefactory was incorrectly expanding function-like macros during `##` token pasting, violating C99 §6.10.3.3 which mandates that operands of `##` should NOT be macro-expanded before concatenation.

**Impact**: Caused SIGSEGV in `test_ffmpeg` when processing complex standard library macros like `INT64_MAX` which expands to `(__INT64_C(9223372036854775807))` where `__INT64_C(c)` is defined as `c ## L`.

**Fix**: Removed macro expansion logic from `collate()` function in `src/yylex.c:1749-1797`. Now matches GCC behavior exactly.

**Test Updates**: Updated 5 test cases to match correct GCC preprocessor behavior:

* `test_collate_empty`
* `test_token_pasting_with_expansion`
* `test_token_pasting_with_expansion_lhs`
* `test_token_pasting_with_expansion_rhs`
* `test_token_pasting_with_illegal_expansion`

==== Memory Scaling Improvements

**Problem**: Large projects like ffmpeg were hitting the 30MB `stackMemory` limit during symbol table construction.

**Root Cause**: Stack memory is a persistent arena allocator that accumulates symbol tables across all parsed files. Growth is expected and normal for large projects.

**Fix**: Increased `SIZE_stackMemory` from 30MB to 100MB in `src/constants.h:19`.

**Diagnostic Additions**: Added nesting level and stack index tracking in `src/xref.c` to monitor memory usage patterns and detect unbalanced block nesting.

==== Caching System Removal

**Decision**: Removed the complex lexem stream caching mechanism to enable architectural refactoring.

**Impact**: Performance regression for large multi-file parsing (6.4× slowdown on test_ffmpeg/test_systemd), but enables critical modernization work.

**Rationale**: The ~300 lines of cache code were deeply intertwined with parsing and memory management, blocking refactoring efforts. Removal provides clearer code structure at the cost of temporary performance regression.

**See**: link:../adr/0012-remove-lexem-stream-caching.md[ADR-0012: Remove Lexem Stream Caching] for detailed rationale, trade-offs, and future optimization strategies.

=== Short-term Goals (Next 3-6 Months)

==== Test Coverage Expansion

*Current Status*: ~80% coverage, ongoing improvement

*Priority*: HIGH

*Goals*:

* Achieve 85%+ coverage for core modules
* Add focused tests for macro expansion subsystem
* Expand coverage for LSP integration points
* Systematic testing of error handling paths

==== LSP Feature Completeness

*Current Status*: Basic LSP communication works, features not yet accessible

*Priority*: HIGH

*Goals*:

* Wire up existing symbol navigation to LSP protocol
* Implement `textDocument/definition` using reference database
* Implement `textDocument/references`
* Implement `textDocument/hover` with symbol information
* Enable `textDocument/completion` for basic completion

*Approach*: Leverage existing reference database (`refTab`) and symbol tables - no major architectural changes needed initially.

==== Documentation Completeness

*Current Status*: Architecture documentation mostly complete

*Priority*: MEDIUM

*Goals*:

* Complete Structurizr C4 model with all major components
* Document memory management strategies across all arenas
* Create user guide for LSP integration
* Document LSP vs Emacs feature parity matrix

=== Medium-term Goals (6-12 Months)

These goals are detailed in <<16-proposed-refactorings.adoc#,Chapter 16: Proposed Refactorings>>. The roadmap establishes priority ordering:

==== 1. LexemStream API Improvements

*Reference*: <<16-proposed-refactorings.adoc#,Proposed Refactorings - LexemStream API Improvements>>

*Priority*: HIGH (Foundation for other refactorings)

*Rationale*: The macro expansion code suffers from pointer parameter proliferation (6+ parameters per function). Adding a manipulation API to `LexemStream` (similar to `LexemBuffer`) will simplify buffer management and reduce error-prone pointer arithmetic.

*Impact*:

* Reduces `collate()` from 6 parameters to 3-4
* Centralizes buffer management logic
* Enables clearer ownership semantics
* Foundation for macro module extraction

*Estimated Effort*: 3-4 weeks

* Week 1: Design and implement core API
* Week 2: Refactor `copyRemainingLexems()` and `collate()` as proof-of-concept
* Week 3-4: Migrate remaining macro expansion functions

==== 2. Extract Macro Expansion Module

*Reference*: <<16-proposed-refactorings.adoc#macro-expansion-module,Proposed Refactorings - Extract Macro Expansion Module>>

*Priority*: MEDIUM (Depends on LexemStream API)

*Rationale*: `yylex.c` is 2353 lines combining lexing, file management, preprocessor directives, and macro expansion (~800 lines). Extracting macro expansion improves modularity and testability.

*Impact*:

* Reduces yylex.c by 34% (~800 lines)
* Enables independent testing of macro expansion
* Clearer separation: lexing vs. preprocessing
* Facilitates future C++ macro support

*Estimated Effort*: 4-6 weeks

* Week 1-2: Create module structure and move memory management
* Week 3-4: Migrate token processing and expansion logic
* Week 5-6: Integration, testing, and documentation

==== 3. Header Re-parsing Optimization

*Priority*: MEDIUM (Addresses caching removal performance regression)

*Problem*: After removing the lexem stream cache, each source file re-parses all its included headers. For projects like ffmpeg with 2616 files including ~30-50 common headers each, this creates 78,000-130,000 redundant parsing operations.

*Proposed Solutions* (in order of implementation):

**Phase 1: Incremental `-create` Mode**

Make `-create` operations incremental by default:

[source,c]
----
c-xref -create
  → Check .cx database for each file
  → Only parse files that are:
     - Not in database, OR
     - Modified since last parse (mtime check)
  → Significantly faster for iterative development
----

*Impact*:
* Second and subsequent `-create` runs become near-instant if no files changed
* Leverages existing file modification tracking (`updateFileModificationTracking()`)
* No architectural changes needed - just skip parsing if DB is current
* Remains fully compatible with existing workflows

*Estimated Effort*: 1-2 weeks

**Phase 2: Preprocessor Dependency Caching**

Cache the **include graph** (which files include which headers) separately from parse results:

[source,c]
----
// Lightweight structure - much smaller than full parse cache
typedef struct {
    int fileNumber;
    int includeCount;
    int includedFiles[]; // Array of file numbers
    time_t lastChecked;
} IncludeDependencyCache;
----

*Benefits*:
* Fast closure computation without re-preprocessing
* Track which files need reparsing when a header changes
* Much simpler than full lexem stream caching
* ~1KB per source file vs. ~100KB+ for full token cache

*Estimated Effort*: 3-4 weeks

**Phase 3: Selective Header Caching** (Future optimization)

After architecture is clean, consider lightweight header caching:

* Cache **only system headers** (unlikely to change): `<stdio.h>`, `<stdlib.h>`, etc.
* Project headers always re-parsed (change frequently during development)
* Cache key: (header path, mtime, compiler flags) → tokenized stream
* Much simpler than removed cache: no cache points, no parser state snapshots

*Design Constraint*: Any future caching must be **optional and transparent**:
* Must work without cache (on-demand parsing as fallback)
* Cache is pure optimization, not architectural requirement
* Clear separation between parsing logic and caching logic

*Estimated Effort*: 6-8 weeks (only after unified database complete)

==== 4. Clean Persistence Store Abstraction

*Reference*: <<16-proposed-refactorings.adoc#clean-persistence-store,Proposed Refactorings - Clean Persistence Store Abstraction>>

*Priority*: HIGH (Foundation for Unified Symbol Database)

*Rationale*: The `cxfile` module currently mixes persistence (reading/writing .cx files), search operations, and menu creation logic. This tight coupling prevents architectural improvements like LSP integration and alternative storage backends.

*Key Problem*: Code conflates two distinct concepts:
* **Reference Database** (in-memory `referenceableItemTable` - the source of truth)
* **Persistence Store** (.cx files on disk - durable cache)

Currently `.cx` files are sometimes treated as authoritative, when they should be just a cache.

*Impact*:

* Creates two clean layers: smart in-memory database vs. dumb durable storage
* Enables testing without .cx files (mock persistence layer)
* Foundation for LSP `textDocument/didChange` integration
* Allows future storage backend alternatives (SQLite, etc.)
* Removes ~200 lines of mixed-responsibility code

*Estimated Effort*: 4-6 weeks

* Week 1-2: Create `persistence_store.h` and `reference_database.h` facades
* Week 3: Extract search/unused-detection logic to proper modules
* Week 4: Hide implementation details (`cxFileHashNumberForSymbol` becomes static)
* Week 5-6: Testing, documentation, and cleanup

==== 5. Unified Symbol Database Architecture

*Reference*:
* <<16-proposed-refactorings.adoc#unified-symbol-database,Proposed Refactorings - Unified Symbol Database Architecture>>
* link:../adr/0014-adopt-on-demand-parsing-architecture.md[ADR-0014: Adopt On-Demand Parsing Architecture]

*Priority*: HIGH (Enables true on-demand LSP)

*Dependencies*: Clean Persistence Store Abstraction (item 4 above)

*Rationale*: Transition from batch-mode (mandatory `-create`) to on-demand parsing where operations work immediately. Builds on the clean persistence layer to add smart invalidation, dependency tracking, and unified client interface.

*Key Benefits*:
* Zero cold start - no upfront `-create` required
* Always up-to-date - automatic modification tracking
* LSP-native - perfect fit for language server architecture
* Single code path for Emacs and LSP clients
* Smart logic lives in in-memory layer, persistence is just durable cache

*Implementation Plan* (see link:../adr/0014-adopt-on-demand-parsing-architecture.md[ADR-0014] for architecture details):
* Phase 1: Incremental `-create` (1-2 weeks)
* Phase 2: On-demand goto-definition proof-of-concept (3-4 weeks)
* Phase 3: Extend to all refactorings (6-8 weeks)
* Phase 4: Deprecate mandatory `-create` (2 weeks)

*Estimated Effort*: 12-16 weeks total

*Accepted Trade-offs*:
* First operation on huge projects may have latency (1-5s)
* Limited detection of archaic `extern` in .c files (see link:../adr/0013-limited-extern-detection-in-c-files.md[ADR-0013])
* These trade-offs enable modern, responsive IDE integration

=== Long-term Vision (12-24 Months)

==== On-Demand Incremental Architecture for LSP

*Current Limitation*: Stack memory accumulates symbol tables across all files forever. This works for batch cross-referencing but is incompatible with long-running LSP servers handling file edits.

*Vision*: Enable true on-demand, per-file parsing suitable for LSP `textDocument/didChange` events.

===== Two-Phase Architecture

**Phase 1: Batch Indexing** (Current behavior, optimized)

----
For each file in project:
    Parse file → populate refTab → discard stackMemory symbols

Result: refTab contains all references, stackMemory reset between files
----

**Phase 2: LSP On-Demand** (Future capability)

----
Load refTab from .cx files (persistent cache)

On textDocument/didChange(file):
    1. Remove old references for file from refTab
    2. Reparse file → update refTab with new references
    3. Reset stackMemory (symbols discarded, only refTab persists)
    4. Navigation uses refTab, not stackMemory symbols!
----

===== Key Architectural Insights

* **Navigation uses refTab, not stackMemory**: This is crucial - symbol lookup queries the reference table, not the ephemeral symbol structures
* **stackMemory can be reset per-file**: As long as refTab is updated first
* **Incremental file updates become possible**: Parse → update refTab → discard symbols
* **Backward compatible**: Batch mode continues to work exactly as before

===== Memory Management Strategy

After unified symbol database is complete, investigate:

* Per-file stackMemory reset after populating refTab
* Separation of navigation data (refTab - persistent) from parsing data (stackMemory - ephemeral)
* Smart arena allocation strategies for long-running servers
* Background garbage collection for unused symbol data

*Estimated Effort*: 16-20 weeks (major architectural work)

==== Full LSP Protocol Compliance

*Dependencies*: Unified symbol database, on-demand architecture

*Goals*:

* Complete implementation of core LSP features:
** `textDocument/definition` ✓ (basic navigation exists)
** `textDocument/references` ✓ (reference database exists)
** `textDocument/hover` (symbol information)
** `textDocument/completion` ✓ (completion system exists)
** `textDocument/rename` ✓ (refactoring engine exists)
** `textDocument/documentSymbol` (symbol outline)
** `textDocument/formatting` (if desired)
** `workspace/symbol` (project-wide symbol search)

* Performance optimization for large projects:
** Lazy loading of symbol data
** Incremental parsing on file changes
** Background indexing
** Memory-mapped `.cx` file access

* Multi-workspace support
* Configuration via LSP initialization options

*Estimated Effort*: 20-24 weeks (building on unified database)

==== Modern IDE Integration Showcase

*Dependencies*: Full LSP compliance

*Goals*:

* **VS Code Extension**: Official c-xrefactory extension with feature parity to Emacs
* **Vim/Neovim Support**: LSP client configuration and documentation
* **Other IDEs**: Ensure LSP implementation works with CLion, Qt Creator, etc.
* **Feature Demonstrations**: Video tutorials showing refactoring capabilities
* **Benchmark Comparisons**: Performance vs. clangd, ccls for large C codebases

*Marketing*:

* Emphasize unique C-specific features (macro understanding, Yacc support)
* Highlight safe refactoring capabilities
* Target embedded systems and legacy C projects

=== Migration and Compatibility Strategy

==== Backward Compatibility Guarantee

* Existing Emacs workflows will continue to work unchanged
* `.cx` file format remains compatible (or auto-migrates transparently)
* Command-line interface preserved (though some commands may become no-ops)
* All existing refactoring operations maintain behavior

==== Deprecation Path

When unified symbol database is complete (see link:../adr/0014-adopt-on-demand-parsing-architecture.md[ADR-0014]):

* `-create` becomes optional (auto-triggers on first operation if needed)
* `-update` becomes automatic (modification time checking)
* Mode flags (`FILE_BASED`, `ON_DEMAND`) deprecated internally
* User-visible options remain for backward compatibility but may have no effect

**Design Principle**: Zero breaking changes - existing workflows continue to work, new capabilities added transparently.

==== Testing Strategy

Throughout all changes:

* **Zero test regressions** - 140+ test suite must pass
* **Coverage maintenance** - keep ~80%+ coverage during refactoring
* **Performance validation** - no >5% regression on large projects
* **Integration testing** - both Emacs and LSP workflows tested

=== Success Metrics

==== Technical Metrics

* **Test Coverage**: Maintain 80%+, target 85%+
* **Response Time**: LSP `textDocument/definition` < 100ms for 90th percentile
* **Memory Efficiency**: LSP server < 500MB RAM for 1M LOC project
* **Startup Time**: Zero cold start delay (no mandatory `-create`)

==== Adoption Metrics

* **VS Code Extension**: 1000+ downloads in first 6 months
* **GitHub Stars**: 500+ (currently ~150)
* **Issue Response**: <48 hours median time to first response
* **Documentation**: 100% of features documented with examples

==== Community Metrics

* **Contributors**: 5+ active contributors beyond maintainer
* **LSP Compatibility**: Works with 3+ major IDEs (VS Code, Vim, CLion)
* **User Satisfaction**: Positive feedback on LSP integration

=== Risk Management

==== Technical Risks

[cols="1,1,2"]
|===
|Risk |Likelihood |Mitigation

|Breaking existing Emacs users
|Medium
|Maintain strict backward compatibility, extensive testing, staged rollout

|Performance regression
|Medium
|Profile before/after each change, performance test suite, optimization budget

|LSP protocol complexity
|Low
|Use existing battle-tested LSP libraries, focus on core features first

|Memory leaks in long-running server
|Medium
|Careful arena allocator design, memory profiling, leak detection tools

|Difficulty attracting contributors
|High
|Excellent documentation, beginner-friendly issues, responsive maintainer

|Competing with clangd
|High
|Focus on unique strengths: macro understanding, Yacc support, safe refactoring
|===

==== Mitigation Strategies

* **Incremental delivery**: Each phase provides standalone value
* **Continuous testing**: Never sacrifice test coverage for features
* **User feedback loops**: Early LSP alpha with select users
* **Fallback options**: Keep old code paths during transition
* **Documentation first**: Write the docs before the code

=== Next Actions

Priority tasks for immediate action:

1. **Complete LSP handler wiring** (1-2 weeks)
   * Map existing navigation functions to LSP requests
   * Test with real LSP client (VS Code)
   * Document any gaps

2. **Design LexemStream API** (1 week)
   * Finalize interface based on proposal
   * Create initial implementation
   * Write unit tests

3. **Plan unified database refactoring** (2 weeks)
   * Detailed design document
   * Identify all affected code paths
   * Prototype dependency-driven scanning

4. **Establish performance baseline** (1 week)
   * Measure current Emacs operation speeds
   * Profile memory usage patterns
   * Document acceptable overhead budgets

=== Conclusion

The roadmap balances immediate user value (LSP features, bug fixes) with long-term architectural health (unified database, modular design). Each phase builds on previous work, with clear success metrics and risk mitigation strategies.

The end goal is a c-xrefactory that is:

* **Zero-configuration**: Works immediately on any C project
* **Modern**: First-class LSP support for all IDEs
* **Powerful**: Unique C-specific features unmatched by competitors
* **Maintainable**: Clean architecture enabling continued evolution
* **Backward compatible**: Existing Emacs users unaffected

This transformation from a 1990s batch cross-referencer to a modern, on-demand LSP server is achievable through careful incremental refactoring guided by comprehensive tests.

=== Related Architecture Decision Records

Key architectural decisions supporting this roadmap:

* link:../adr/0012-remove-lexem-stream-caching.md[ADR-0012: Remove Lexem Stream Caching] - Documents rationale for accepting 6.4× performance regression to enable refactoring
* link:../adr/0013-limited-extern-detection-in-c-files.md[ADR-0013: Limited Extern Detection] - Accepted limitation for archaic C patterns
* link:../adr/0014-adopt-on-demand-parsing-architecture.md[ADR-0014: On-Demand Parsing] - Core architectural shift from batch to on-demand

See also:
* <<16-proposed-refactorings.adoc#,Chapter 16: Proposed Refactorings>> for detailed technical proposals
* link:../adr-process.md[ADR Process Guide] for complete decision history and ADR conventions

---

NOTE: This roadmap is a living document. As priorities shift and new insights emerge, it will be updated to reflect current understanding and goals.
